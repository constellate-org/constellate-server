{
  "setup_mpl": [],
  "setup_panel": [],
  "stars": [
    {
      "kind": "pure_markdown",
      "markdown": "# Multivariable Calculus Concepts\n\nAh, multivariable calculus. Because single-variable calculus was too easy, apparently.\n\nThis is a whirlwind tour of several concepts in multivariable calculus that benefit from visuals that you can't make in Desmos. We're going to start with vectors and what they are, and end with some fancy calculus stuff with lots of cool symbols.",
      "star_id": "meh75bw4"
    },
    {
      "kind": "pure_markdown",
      "markdown": "## Prologue: Vector Spaces\n\nA lot of useful math follows a process of discovery, characterization, abstraction, and generalization:\n * We find some interesting mathematical object and study it, discovering interesting things.\n * We then *characterize* it using a set of properties, some hand-picked set of those interesting things we found.\n * We then *abstract* those properties, starting from the top using only those properties.\n * Once we've done that, any results we use now *generalize* to any time those properties hold, even if it wasn't what we originally had in mind.\n\nHere's a simple example. We start with the operation of integer exponentiation as repeated multiplication: $2^3 = 2 \\times 2 \\times 2$. \n * We note some useful properties: $b^1 = b, b \\times b^1 = b^2$, and more generally $b^m \\times b^n = b^{m + n}$.\n * We *abstract* what we're studying: we define exponentiation as specifically a function $\\exp$ with base $b$ such that $\\exp(m) \\times \\exp(n) = \\exp(m + n)$ and $\\exp(1) = b$, without ever specifically mentioning the idea of repeated multiplication we started with.\n * Using this definition and nothing else, we can *generalize*: we can show $\\exp(0) = 1, \\exp(-1) = \\frac{1}{b}, \\exp(\\frac{1}{2}) = \\sqrt{b}$, and a host of other useful facts that improve on our original definition.\n\nWe end with a much more useful tool than what we had when we began. So why do I bring this up? Well, it's exactly this process that will lead us to vector spaces, linear algebra, and vector calculus\u2014let's begin!",
      "star_id": "pxeuaSdN"
    },
    {
      "kind": "pure_markdown",
      "markdown": "I imagine you're familiar with lines: $f(x) = mx + b$. You probably know a lot of things about lines already! Let's try and generalize this definition, as we did with exponentiation before. We'll take $x$ to be an object that has just the properties we absolutely need to set this up and have it look vaguely line-y (to sound more mature, we'll say *linear* instead from now on). Specifically, we need to be able to multiply $x$ by $m$, which we'll keep as a real number. We'll also need to add things to $x$. We'll make $b$ the same type of thing as $x$.\n\nSo $x$ is a member of some set $V$ that has two functions defined on it:\n * Addition, $A: V \\times V \\rightarrow V$\n * Scalar multiplication, $S: \\R \\times V \\rightarrow V$.\n\nJust knowing these functions exist doesn't really let us prove anything, however. What we need is to characterize the important properties of addition and multiplication we want our $X$ set to observe.",
      "star_id": "miDyAfnn"
    },
    {
      "kind": "pure_markdown",
      "markdown": "### The Definition of a Vector Space\n\nThere are eight *axioms* we will use: without these, even if you call it addition and multiplication, it really isn't. We will also start using uppercase to refer to members of this new set $V$ we're trying to define: anything in lowercase is a real number, or to be extra clear we'll say a *scalar*.\n\n---------------------------\n\nLet $V$ be a set on which addition and multiplication are defined. If the following hold, then we say $V$ is a *vector space*, and we call its elements *vectors*.\n\n1. **Commutativity of Addition**\n\n  For all $X, Y \\in V$, $X + Y = Y + X$.\n  \n2. **Associativity of Addition**\n\n  For all $X, Y, Z \\in V$, $(X + Y) + Z = X + (Y + Z)$.\n  \n3. **Existence of Additive Identity**\n\n  There exists some element $\\vec{0} \\in V$ such that, for all $X \\in V$, $\\vec{0} + X = X + \\vec{0} = X$.\n  \n4. **Existence of Additive Inverse**\n\n  For all $X \\in V$, there exists some $-X \\in V$ such that $X + (-X) = 0$.\n\n5. **Associativity of Multiplication**\n\n  For all $X \\in V$ and $r, s \\in \\R$, $r(sX) = (rs)X$.\n\n6. **Distributivity of Scalar Addition**\n\n  For all $X \\in V$ and $r, s \\in \\R$, $(r + s)X = rX + sX$.\n\n7. **Distributivity of Vector Addition**\n\n  For all $X, Y \\in V$ and $r \\in \\R$, $r(X + Y) = rX + rY$.\n\n8. **Existence of Scalar Multiplicative Identity**\n\n  For all $X$, $1X = X$.\n\n-----------------------------------------\n\nNote that, technically, $V$ itself isn't a vector space: the combination of $V$, addition, multiplication, and additive identity is a vector space. In practice, addition and multiplication are usually defined in fairly clear ways, so we tend to elide that information and just say \"$\\R$ is a vector space.\"\n\nWhew, that's a lot to write out! Read this over a couple of times, and see if everything makes sense. Make sure everything works for $\\R$, because if that isn't a vector space then we've completely missed the mark in generalizing those concepts...",
      "star_id": "94Xgdjslz"
    },
    {
      "kind": "pure_markdown",
      "markdown": "Something I highly recommend, when seeing a hefty new definition for the first time, is to really kick the tires and see what makes it tick. These are questions you should usually ask yourself when encountering a new definition. The best way, IMO, to start out doing that is to see if things fit your definition. That's how you really internalize what the definition is. Here are some test cases to think about: are these vector spaces? If so, how? If not, why not?\n\n * $\\R$\n * $\\mathbb{C}$\n * The interval $[0, 1)$, set up so that where addition and multiplication wrap around, e.g., $0.5 + 0.75 = 0.25$ and $7 * 0.3 = 0.1$\n * The space of all real-to-real functions $f: \\R \\rightarrow \\R$, with addition and multiplication done point-by-point\n * The space of all real-to-real functions that are not continuous everywhere\n * The set of all single-variable polynomials\n * The upper right quadrant of the plane: $\\{(x, y)\\ |\\ x \\ge 0, y \\ge 0 \\}$\n * The set of all triples $\\{(a, b, c)\\ |\\ 2a + 3b - 4 = 0, 3a - 2b + 5 = 0 \\}$, with addition adding a, b, and c separately and multiplication multiplying each component separately",
      "star_id": "rv6cSYpl5"
    },
    {
      "kind": "pure_markdown",
      "markdown": "Showing things are or aren't vector spaces lets you see how widely applicable vector spaces can be. Now let's get the smallest taster of what we can prove about vector spaces. Remember that we're proving this for every single vector space at once, which is a mighty nice time saver.\n\nFor an arbitrary vector space $V$, prove the following:\n\n * For all $X \\in V$, $0X = \\vec{0}$.\n * For all $r \\in \\R$, $r\\vec{0} = \\vec{0}$.\n * The additive identity $\\vec{0}$ is unique.\n * The additive inverse $-X$ is unique for any $X$, and it is equal to $(-1)X$.",
      "star_id": "z1JitNzL"
    },
    {
      "kind": "pure_markdown",
      "markdown": "### Linearity\n\nVector spaces are insanely useful all over the place, including multivariable calculus. We want to bring in one more important definition, following a common pattern in math: when we first come up with some class of things, we tend to also be interested in the relationships between them that preserve the properties we just spent so long describing.\n\nSpecifically, we will define a special class of transformations:\n\n> Let $V$ and $W$ be vector spaces. A transformation $T: V \\rightarrow W$ is *linear* if T preserves scalar addition and multiplication:\n> * For all $A, B \\in V$, $T(A) +_W T(B) = T(A +_V B)$.\n> * For all $A \\in V$ and $r \\in R$, $r T(A) = T(r A)$.",
      "star_id": "UMogRPM0"
    },
    {
      "kind": "pure_markdown",
      "markdown": "Same as last time, let's take a second to process this definition.\n\n * Note that the set of lines through the origin, $T(x) = mx$, is a linear transformation from $\\R$ to $\\R$. This motivates the name linear: like a line.\n * Are rotations linear, as a map from $\\mathbb{C}$ to $\\mathbb{C}$? What about reflections or translations?\n * Consider the vector space of all differentiable functions from $\\R$ to $\\R$, which I'll call $F_D$. Call the function space of all functions from $\\R$ to $\\R$ just $F$. Show that $D: F_D \\rightarrow F$, the operation of differentiation, is linear.\n * Similarly, can you show that the function $L: F_D \\rightarrow \\R$ given by $L(F) = \\lim_{x \\rightarrow 0} F(x)$ is linear or show that it isn't?\n * Consider the mapping $T: F_D \\rightarrow P_n$, where $F_D$ is the space of infinitely differentiable real-valued functions and $P_n$ is the set of polynomials of degree $n$, given by n-term Taylor expansion. Is this mapping linear?\n\nWe're finally done with basic definitions! Now's a good time to take a breather, pat yourself on the back, and do something else: until then!",
      "star_id": "tto6O6Cn"
    }
  ],
  "breadcrumbs": [
    [],
    [
      0
    ],
    [
      0,
      1
    ],
    [
      0,
      1
    ],
    [
      0,
      1,
      3
    ],
    [
      0,
      1,
      3
    ],
    [
      0,
      1
    ],
    [
      0,
      1,
      6
    ]
  ],
  "title": "Multivariable Calculus Concepts",
  "star_titles": [
    "Multivariable Calculus Concepts",
    "Prologue: Vector Spaces",
    "",
    "The Definition of a Vector Space",
    "",
    "",
    "Linearity",
    ""
  ]
}